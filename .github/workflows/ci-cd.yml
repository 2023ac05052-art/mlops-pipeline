name: CI/CD Pipeline

# Specifies the events that trigger the workflow
on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
      - develop # You can also add other branches here

jobs:
  lint:
    runs-on: self-hosted

    steps:
    - name: Checkout code
      uses: actions/checkout@v2
      
    - name: Show working directory
      run: |
        echo "GitHub workspace: $GITHUB_WORKSPACE"
        pwd
        ls -la
        echo "Current user: $(whoami)"
        echo "Docker version: $(docker --version)"
        echo "Docker info: $(docker info)"

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.8'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install flake8

    - name: Lint code
      run: |
        flake8 . --exit-zero --statistics > flake8_stats.txt
        error_count=$(grep -oP '^\d+' flake8_stats.txt | awk '{s+=$1} END {print s}')
        if [ "$error_count" -ge 10 ]; then
            echo "Linting failed with $error_count errors."
            exit 1
        else
            echo "Linting passed with $error_count errors."
        fi

  validate_data:
    runs-on: self-hosted
    needs: lint
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'
          
      - name: Install dependencies and DVC
        run: |
          python -m pip install --upgrade pip
          # We need to install dvc here to pull the data
          pip install pandas pydantic dvc s3fs

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: 'us-east-1' # Replace with your S3 bucket region

      - name: Configure DVC remote
        run: |
          # This step is crucial for DVC to know where to pull from.
          # We'll use your configured remote here.
          dvc remote add -d myremote s3://my-dvc-bucket/dvc-storage

      - name: Pull data with DVC
        run: |
          # This step pulls the data file from the DVC remote cache
          dvc pull --force
          
      - name: Validate input data with Pydantic
        run: |
          python validate_data.py
          
      - name: Push metrics to Prometheus Pushgateway
        run: |
          echo "Pushing data validation metrics to Prometheus"
          curl -X POST -H "Content-Type: text/plain" --data-binary @- http://10.243.245.246:9091/metrics/job/ci-cd-validation <<EOF
          # HELP validation_successes_total Total number of successful validations.
          # TYPE validation_successes_total counter
          validation_successes_total 1
          EOF
          
  test:
    runs-on: self-hosted
    needs: validate_data

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas scikit-learn joblib mlflow dvc

      - name: Prepare data and train model
        run: |
          # The dvc pull is now done in the validate_data job,
          # so we don't need it here unless other data is needed.
          python prepare_data.py
          python train_model.py
        
  build_and_deploy:
    runs-on: self-hosted
    needs: test

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Print current user
      run: |
        whoami

    - name: Log in to Docker Hub
      run: |
        echo "${{ secrets.DOCKER_PASSWORD }}" | docker login -u "${{ secrets.DOCKER_USERNAME }}" --password-stdin

    - name: Build Docker image
      run: |
        docker build -t mlops_80_model_img .

    - name: Push Docker image to Docker Hub
      run: |
        docker tag mlops_80_model_img ${{ secrets.DOCKER_USERNAME }}/mlops_80_model_img:latest
        docker push ${{ secrets.DOCKER_USERNAME }}/mlops_80_model_img:latest

    - name: Stop and Remove Existing Container
      run: |
        if [ "$(docker ps -q -f name=mlops_80_model_app)" ]; then
          docker stop mlops_80_model_app
          docker rm mlops_80_model_app
        fi

    - name: Deploy Docker container
      run: |
        docker run -d -p 5000:5000 --name mlops_80_model_app ${{ secrets.DOCKER_USERNAME }}/mlops_80_model_img:latest
